{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "27c67255",
   "metadata": {},
   "source": [
    "# Congratulations to Completing Regression & Classification Module ðŸ¥‚"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bf7aeae",
   "metadata": {},
   "source": [
    "## Clustering\n",
    "\n",
    "- Clustering is similar to classification, but the basis is different. In Clustering **you donâ€™t know what you are looking for**, and you are trying to **identify some segments or clusters** in your data.\n",
    "- When you use clustering algorithms on your dataset, unexpected things can suddenly pop up like structures, clusters and groupings you would have never thought of otherwise.\n",
    "- Let's start with **K-Means Clustering**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d00ca570",
   "metadata": {},
   "source": [
    "# K-Means Clustering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95e2cbf7",
   "metadata": {},
   "source": [
    "- K-Means Clustering is the most popular clustering algorithm out there.\n",
    "- It will cluster or group the dataset by given number of cluster K."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50e0379b",
   "metadata": {},
   "source": [
    "## Algorithm\n",
    "\n",
    "- **Step 1** : Choose the number K of cluster.\n",
    "- **Step 2** : Select random K points from the graph which is our centroids. (not necessary from dataset).\n",
    "- **Step 3** : Find the closest data points to the centroids & assign to them. (will form K cluster).\n",
    "- **Step 4** : Place the centroid in center of the cluster.\n",
    "- **Step 5** : Find the closest data points to the new centroids & reassign the label.\n",
    "- **Step 6** : Repeat **Step 4 & 5** if their any reassign to the data points, else END.\n",
    "- **END** : Your model is ready"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f2ed58c",
   "metadata": {},
   "source": [
    "## Manual Example"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1e8dcc7",
   "metadata": {},
   "source": [
    "|||\n",
    "|:---:|:---:|\n",
    "|<img src=\"../static/k_means_ppt_1.png\" alt=\"k_means_ppt_1.png\" width=\"400\">|<img src=\"../static/k_means_ppt_2.png\" alt=\"k_means_ppt_2.png\" width=\"400\">|\n",
    "|<img src=\"../static/k_means_ppt_3.png\" alt=\"k_means_ppt_3.png\" width=\"400\">|<img src=\"../static/k_means_ppt_4.png\" alt=\"k_means_ppt_4.png\" width=\"400\">|\n",
    "|<img src=\"../static/k_means_ppt_5.png\" alt=\"k_means_ppt_3.png\" width=\"400\">|<img src=\"../static/k_means_ppt_6.png\" alt=\"k_means_ppt_6.png\" width=\"400\">|\n",
    "|<img src=\"../static/k_means_ppt_7.png\" alt=\"k_means_ppt_7.png\" width=\"400\">|<img src=\"../static/k_means_ppt_8.png\" alt=\"k_means_ppt_8.png\" width=\"400\">|\n",
    "|<img src=\"../static/k_means_ppt_9.png\" alt=\"k_means_ppt_9.png\" width=\"400\">|<img src=\"../static/k_means_ppt_10.png\" alt=\"k_means_ppt_10.png\" width=\"400\">|\n",
    "|<img src=\"../static/k_means_ppt_11.png\" alt=\"k_means_ppt_11.png\" width=\"400\">|<img src=\"../static/k_means_ppt_12.png\" alt=\"k_means_ppt_12.png\" width=\"400\">|\n",
    "|<img src=\"../static/k_means_ppt_13.png\" alt=\"k_means_ppt_13.png\" width=\"400\">|<img src=\"../static/k_means_ppt_14.png\" alt=\"k_means_ppt_14.png\" width=\"400\">|\n",
    "|||"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "573a65f6",
   "metadata": {},
   "source": [
    "## Random Initialization Trap"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58af6fc1",
   "metadata": {},
   "source": [
    "- In our **``Step 2 : Select random K points from the graph which is our centroids. (not necessary from dataset).``**\n",
    "- We need to be very careful while choosing the random K points.\n",
    "- I will show you 2 cases where we are trying to place the random point, that change our clusters.\n",
    "\n",
    "#### Case 1:\n",
    "- We have selected the random K points for the given dataset in the correct places.\n",
    "\n",
    "<img src=\"../static/k_means_random_initialization_trap_1.png\" alt=\"k_means_random_initialization_trap_1.png\" width=\"400\">\n",
    "\n",
    "#### Case 2:\n",
    "- If we select random K points in different place which is not relevant to the dataset then entire model will be changes.\n",
    "\n",
    "<img src=\"../static/k_means_random_initialization_trap_2.png\" alt=\"k_means_random_initialization_trap_2.png\" width=\"400\">\n",
    "\n",
    "#### Solution (K-Means++):\n",
    "- There is no specific solution for choosing the random points, but we have **K-Means++** to avoid these kinds of issues.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "287fba53",
   "metadata": {},
   "source": [
    "## Selecting The Number Of Clusters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2e9df5b",
   "metadata": {},
   "source": [
    "- From our **``Step 1 : Choose the number K of cluster.``**\n",
    "- We know that, we manually need to choose the number of K cluster count.\n",
    "- We can choose 1(min) to n(max) as the K value. *(where n=total number of dataset)*\n",
    "- I have a doubt that how we can choose this K value which given K proper split of our dataset? *(Hope you also have same doubt)*\n",
    "- Answer is, we can use **Elbow-Method using WCSS** value.\n",
    "\n",
    "### WCSS\n",
    "- Let's assume we take K=3 for now, then we can find the WCSS value from given equation.\n",
    "\n",
    "    <img src=\"../static/k_means_wcss_eqn_1.png\" alt=\"k_means_wcss_eqn_1.png\">\n",
    "- As we can see, we have 3 Summations for 3 clusters.\n",
    "\n",
    "    <img src=\"../static/k_means_wcss_eqn_2.png\" alt=\"k_means_wcss_eqn_2.png\">\n",
    "    \n",
    "> Where, we found summation (Î£) of square (x<sup>2</sup>) of distance between every point in the cluster (P<sub>i</sub>) & centroid (C<sub>K</sub>).\n",
    "- Similarly, we need to find WCSS for every K values.  \n",
    "\n",
    "### Elbow-Method\n",
    "- Lets plot the graph between K value & WCSS value.\n",
    "\n",
    "<img src=\"../static/k_means_elbow_method.png\" alt=\"k_means_elbow_method.png\">\n",
    "\n",
    "- If you see the chart, we can understand for K values 1, 2, 3, 4 there is a huge loss in WCSS value.\n",
    "- But for 5, 6, 7, 8, 9, 10 values there is not much loss in WCSS value.\n",
    "- So, we can fix with 4 as the K value. (i.e., K=4)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
