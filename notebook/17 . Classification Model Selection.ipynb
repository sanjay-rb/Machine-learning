{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d00ca570",
   "metadata": {},
   "source": [
    "# Classification Model Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76dda459",
   "metadata": {},
   "source": [
    "## Data preprocessing\n",
    "\n",
    "✔️ Import the necessary libraries.\n",
    "\n",
    "✔️ Load dataset (Breast_Cancer.csv).\n",
    "\n",
    "❌ Our dataset doesn't have any missing data.\n",
    "\n",
    "❌ Our dataset doesn't have any string data.\n",
    "\n",
    "✔️ We have 684 data. So, we can split and have 75% for the training set and 25% for the testing set. \n",
    "\n",
    "✔️ Applying feature scaling for the dataset will improve the performance of the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4cd8f5f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries....\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "# setting two digits after decimal point...\n",
    "np.set_printoptions(precision=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "024eb714",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset...\n",
    "dataset = pd.read_csv(r\"../dataset/Breast_Cancer.csv\")\n",
    "X = dataset.iloc[:, :-1].values  # [row, column]\n",
    "y = dataset.iloc[:, -1].values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "138123e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split testing and training dataset...\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.25, random_state=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1f3926c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Performing feature scaling for the independent variable...\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "x_sc = StandardScaler()\n",
    "X_train = x_sc.fit_transform(X_train)\n",
    "X_test = x_sc.transform(X_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2aef8f27",
   "metadata": {},
   "source": [
    "## Train and evaluate the performance of Logistic Regression Classification\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fe24929b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[103   4]\n",
      " [  5  59]]\n",
      "Accuracy score for Logistic Regression Classification : 0.9473684210526315\n"
     ]
    }
   ],
   "source": [
    "# Training....\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "logistic_regression_calssifier = LogisticRegression(random_state=0)\n",
    "logistic_regression_calssifier.fit(X_train, y_train)\n",
    "\n",
    "# Testing....\n",
    "y_pred = logistic_regression_calssifier.predict(X_test)\n",
    "\n",
    "# Confusion Matrix....\n",
    "print(confusion_matrix(y_true=y_test, y_pred=y_pred))\n",
    "# Score....\n",
    "acc_logistic_regression_classification = accuracy_score(\n",
    "    y_true=y_test, y_pred=y_pred)\n",
    "print(\"Accuracy score for Logistic Regression Classification :\",\n",
    "      acc_logistic_regression_classification)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27446f3b",
   "metadata": {},
   "source": [
    "## Train and evaluate the performance of K Nearest Neighbor Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "329c8ff5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[103   4]\n",
      " [  5  59]]\n",
      "Accuracy score for K Nearest Neighbor Classification : 0.9473684210526315\n"
     ]
    }
   ],
   "source": [
    "# Training....\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "k_nn_calssifier = KNeighborsClassifier(n_neighbors=5, p=2, metric=\"minkowski\")\n",
    "k_nn_calssifier.fit(X_train, y_train)\n",
    "\n",
    "# Testing....\n",
    "y_pred = k_nn_calssifier.predict(X_test)\n",
    "\n",
    "\n",
    "# Confusion Matrix....\n",
    "print(confusion_matrix(y_true=y_test, y_pred=y_pred))\n",
    "# Score....\n",
    "acc_k_nearest_neighbor_classification = accuracy_score(\n",
    "    y_true=y_test, y_pred=y_pred)\n",
    "print(\"Accuracy score for K Nearest Neighbor Classification :\",\n",
    "      acc_k_nearest_neighbor_classification)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67d089ff",
   "metadata": {},
   "source": [
    "## Train and evaluate the performance of (SVC) Support Vector Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f8e26b11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[102   5]\n",
      " [  5  59]]\n",
      "Accuracy score for (SVC) Support Vector Classification : 0.9415204678362573\n"
     ]
    }
   ],
   "source": [
    "# Training....\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "from sklearn.svm import SVC\n",
    "svc_calssifier = SVC(kernel=\"linear\", random_state=0)\n",
    "svc_calssifier.fit(X_train, y_train)\n",
    "\n",
    "# Testing....\n",
    "y_pred = svc_calssifier.predict(X_test)\n",
    "\n",
    "# Confusion Matrix....\n",
    "print(confusion_matrix(y_true=y_test, y_pred=y_pred))\n",
    "# Score....\n",
    "acc_svc_support_vector_classification = accuracy_score(\n",
    "    y_true=y_test, y_pred=y_pred)\n",
    "print(\"Accuracy score for (SVC) Support Vector Classification :\",\n",
    "      acc_svc_support_vector_classification)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef77ebaf",
   "metadata": {},
   "source": [
    "## Train and evaluate the performance of Kernel (SVC) Support Vector Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a729375a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[102   5]\n",
      " [  3  61]]\n",
      "Accuracy score for Kernel (SVC) Support Vector Classification : 0.9532163742690059\n"
     ]
    }
   ],
   "source": [
    "# Training....\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "from sklearn.svm import SVC\n",
    "kernel_svc_calssifier = SVC(kernel=\"rbf\", random_state=0)\n",
    "kernel_svc_calssifier.fit(X_train, y_train)\n",
    "\n",
    "# Testing....\n",
    "y_pred = kernel_svc_calssifier.predict(X_test)\n",
    "\n",
    "# Confusion Matrix....\n",
    "print(confusion_matrix(y_true=y_test, y_pred=y_pred))\n",
    "# Score....\n",
    "acc_kernel_support_vector_classification = accuracy_score(\n",
    "    y_true=y_test, y_pred=y_pred)\n",
    "print(\"Accuracy score for Kernel (SVC) Support Vector Classification :\",\n",
    "      acc_kernel_support_vector_classification)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3936bc0f",
   "metadata": {},
   "source": [
    "## Train and evaluate the performance of Naive Bayes Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7a8fa199",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[99  8]\n",
      " [ 2 62]]\n",
      "Accuracy score for Naive Bayes Classification : 0.9415204678362573\n"
     ]
    }
   ],
   "source": [
    "# Training....\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "naive_bayes_calssifier = GaussianNB()\n",
    "naive_bayes_calssifier.fit(X_train, y_train)\n",
    "\n",
    "# Testing....\n",
    "y_pred = naive_bayes_calssifier.predict(X_test)\n",
    "\n",
    "# Confusion Matrix....\n",
    "print(confusion_matrix(y_true=y_test, y_pred=y_pred))\n",
    "# Score....\n",
    "acc_naive_bayes_classification = accuracy_score(y_true=y_test, y_pred=y_pred)\n",
    "print(\"Accuracy score for Naive Bayes Classification :\",\n",
    "      acc_naive_bayes_classification)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c18e4683",
   "metadata": {},
   "source": [
    "## Train and evaluate the performance of Decision Tree Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fe87f657",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[103   4]\n",
      " [  3  61]]\n",
      "Accuracy score for Decision Tree Classification : 0.9590643274853801\n"
     ]
    }
   ],
   "source": [
    "# Training....\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "decision_tree_calssifier = DecisionTreeClassifier(\n",
    "    criterion='entropy', random_state=0)\n",
    "decision_tree_calssifier.fit(X_train, y_train)\n",
    "\n",
    "# Testing....\n",
    "y_pred = decision_tree_calssifier.predict(X_test)\n",
    "\n",
    "# Confusion Matrix....\n",
    "print(confusion_matrix(y_true=y_test, y_pred=y_pred))\n",
    "# Score....\n",
    "acc_decision_tree_classification = accuracy_score(y_true=y_test, y_pred=y_pred)\n",
    "print(\"Accuracy score for Decision Tree Classification :\",\n",
    "      acc_decision_tree_classification)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95c7123b",
   "metadata": {},
   "source": [
    "## Train and evaluate the performance of Random Forest Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b5038b3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[102   5]\n",
      " [  6  58]]\n",
      "Accuracy score for Random Forest Classification : 0.935672514619883\n"
     ]
    }
   ],
   "source": [
    "# Training....\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "random_forest_calssifier = RandomForestClassifier(\n",
    "    n_estimators=10, criterion='entropy', random_state=0)\n",
    "random_forest_calssifier.fit(X_train, y_train)\n",
    "\n",
    "# Testing....\n",
    "y_pred = random_forest_calssifier.predict(X_test)\n",
    "\n",
    "# Confusion Matrix....\n",
    "print(confusion_matrix(y_true=y_test, y_pred=y_pred))\n",
    "# Score....\n",
    "acc_random_forest_classification = accuracy_score(y_true=y_test, y_pred=y_pred)\n",
    "print(\"Accuracy score for Random Forest Classification :\",\n",
    "      acc_random_forest_classification)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80662fe0",
   "metadata": {},
   "source": [
    "## Which is best for given dataset ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "03240380",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression with accuracy score : 0.9473684210526315\n",
      "K Nearest Neighbor Classification with accuracy score : 0.9473684210526315\n",
      "(SVC) Support Vector Classification) with accuracy score : 0.9415204678362573\n",
      "Kernel (SVC) Support Vector Classification with accuracy score : 0.9532163742690059\n",
      "Naive Bayes Classification with accuracy score : 0.9415204678362573\n",
      "Decision Tree Classification with accuracy score : 0.9590643274853801\n",
      "Random Forest Classification with accuracy score : 0.935672514619883\n",
      "🎉🎉🎉🎉🎉🎉🎉🎉🎉🎉🎉🎉🎉🎉🎉🎉🎉🎉🎉🎉🎉🎉🎉🎉🎉🎉🎉🎉🎉🎉🎉🎉🎉🎉🎉🎉🎉🎉🎉🎉🎉🎉🎉🎉🎉🎉🎉🎉🎉🎉🎉🎉\n",
      "Decision Tree Classification is the best model for given dataset 🥳 with Accuracy score 0.9590643274853801\n",
      "🎉🎉🎉🎉🎉🎉🎉🎉🎉🎉🎉🎉🎉🎉🎉🎉🎉🎉🎉🎉🎉🎉🎉🎉🎉🎉🎉🎉🎉🎉🎉🎉🎉🎉🎉🎉🎉🎉🎉🎉🎉🎉🎉🎉🎉🎉🎉🎉🎉🎉🎉🎉\n"
     ]
    }
   ],
   "source": [
    "accuracy_score_list = {\n",
    "    \"Logistic Regression\": acc_logistic_regression_classification,\n",
    "    \"K Nearest Neighbor Classification\": acc_k_nearest_neighbor_classification,\n",
    "    \"(SVC) Support Vector Classification)\": acc_svc_support_vector_classification,\n",
    "    \"Kernel (SVC) Support Vector Classification\": acc_kernel_support_vector_classification,\n",
    "    \"Naive Bayes Classification\": acc_naive_bayes_classification,\n",
    "    \"Decision Tree Classification\": acc_decision_tree_classification,\n",
    "    \"Random Forest Classification\": acc_random_forest_classification,\n",
    "}\n",
    "# Print final result of all model....\n",
    "for model, accuracy in accuracy_score_list.items():\n",
    "    print(f\"{model} with accuracy score : {accuracy}\")\n",
    "\n",
    "# find best of them....\n",
    "best_of_them = max(accuracy_score_list.values())\n",
    "\n",
    "# Print best of them....\n",
    "for model, r2 in accuracy_score_list.items():\n",
    "    if r2 == best_of_them:\n",
    "        print_me = f\"{model} is the best model for given dataset 🥳 with Accuracy score {r2}\"\n",
    "        print(\"🎉\" * (len(print_me) // 2))\n",
    "        print(print_me)\n",
    "        print(\"🎉\" * (len(print_me) // 2))\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb8481a2",
   "metadata": {},
   "source": [
    "**Note:** Above result is only for the dataset (Breast_Cancer.csv) which we were given as the input. If you change the dataset, the result also changes certainly."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
