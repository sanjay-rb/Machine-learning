{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "d6351ece",
   "metadata": {},
   "source": [
    "# Multiple Linear Regression\n",
    "- We all know that Simple linear regression will be suitable for single independent variable and single dependent variable.\n",
    "- Whereas, Multiple linear regression is used to predict a single dependent variable from will be multiple independent variables. \n",
    "- Number of independent variable (X) = n\n",
    "- Number of dependent variable (Y) = 1\n",
    "- This algorithm follows a multiple linear regression equation\n",
    "<img src=\"../images/multiple_linear_regression_eqn.png\" alt=\"multiple_linear_regression_eqn.png\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22e00e67",
   "metadata": {},
   "source": [
    "## Assumptions of linear regression:-\n",
    "``` \n",
    "Before going to Linear regression usually we do some checks in dataset those are not compulsory but if we do those our  model may give better prediction.\n",
    "```\n",
    "\n",
    "There are four assumptions associated with a linear regression model:\n",
    "1. **Linearity**: The relationship between X and the mean of Y is linear.\n",
    "2. **Homoscedasticity**: The variance of residual is the same for any value of X.\n",
    "3. **Independence**: Observations are independent of each other.\n",
    "4. **Multivariate Normality**: For any fixed value of X, Y is normally distributed.\n",
    "5. **Lack of multicollinearity**: Multicollinearity reduces the precision of the estimated coefficients, which weakens the statistical power of your regression model. You might not be able to trust the p-values to identify independent variables that are statistically significant."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "d94f02d4",
   "metadata": {},
   "source": [
    "## Dummy Variables\n",
    "- Dummy variables are conversion of a categorical variable to vector form only.\n",
    "- Yes, while conversion of categorical variable we need to be very careful about the **Dummy Variable Trap**\n",
    "-  Example Table Column:-\n",
    "\n",
    "<img src=\"../images/dummy_variables_eg_1.png\" alt=\"dummy_variables_eg_1.png\">\n",
    "\n",
    "- When we change category data to vector form, it will look like the below table.\n",
    "- Where columns like Chennai, CBE, Ooty are our Dummy variables for the regression equation.\n",
    "\n",
    "<img src=\"../images/dummy_variables_eg_2.png\" alt=\"dummy_variables_eg_2.png\">\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "add08fc2",
   "metadata": {},
   "source": [
    "## Dummy Variables Trap Removal\n",
    "- We are converting categorical data to pass those dummy variables to the Regression equation.\n",
    "- As we discussed above. We have three dummy variables so, our regression equation will convert into some equation like below.\n",
    "\n",
    "<img src=\"../images/dummy_variables.png\" alt=\"Image\">\n",
    "\n",
    "- You may wonder! We have three dummy variables but, we only use 2 of them where, is 3rd dummy variable?\n",
    "- If your wonder is not a problem, actually b0 is the last dummy variable ie, b0 = Dn-1.\n",
    "- Above process is called dummy variable removal, but need not worry about this because **dummy variable trap** will automatically be removed by **Scikit-Learn** library\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6eede27",
   "metadata": {},
   "source": [
    "## Lots of theory! Let get into code ðŸ˜€"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c806fbb3",
   "metadata": {},
   "source": [
    "## Data preprocessing\n",
    "- Import the necessary libraries.\n",
    "- Load dataset (50_Startups).\n",
    "- Our dataset doesn't have any missing so, we can skip that step.\n",
    "- But we have categorical string data which need to be, converted.\n",
    "- Prepare testing and training dataset.\n",
    "- Linear regression algorithms are an equation type so, it is having a constant to make the model standardize, so we don't need feature scaling for this algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0f45e115",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the necessary libraries.\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0fa43490",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset\n",
      "    R&D Spend  Administration  Marketing Spend       State     Profit\n",
      "0   165349.20       136897.80        471784.10    New York  192261.83\n",
      "1   162597.70       151377.59        443898.53  California  191792.06\n",
      "2   153441.51       101145.55        407934.54     Florida  191050.39\n",
      "3   144372.41       118671.85        383199.62    New York  182901.99\n",
      "4   142107.34        91391.77        366168.42     Florida  166187.94\n",
      "5   131876.90        99814.71        362861.36    New York  156991.12\n",
      "6   134615.46       147198.87        127716.82  California  156122.51\n",
      "7   130298.13       145530.06        323876.68     Florida  155752.60\n",
      "8   120542.52       148718.95        311613.29    New York  152211.77\n",
      "9   123334.88       108679.17        304981.62  California  149759.96\n",
      "10  101913.08       110594.11        229160.95     Florida  146121.95\n",
      "11  100671.96        91790.61        249744.55  California  144259.40\n",
      "12   93863.75       127320.38        249839.44     Florida  141585.52\n",
      "13   91992.39       135495.07        252664.93  California  134307.35\n",
      "14  119943.24       156547.42        256512.92     Florida  132602.65\n",
      "15  114523.61       122616.84        261776.23    New York  129917.04\n",
      "16   78013.11       121597.55        264346.06  California  126992.93\n",
      "17   94657.16       145077.58        282574.31    New York  125370.37\n",
      "18   91749.16       114175.79        294919.57     Florida  124266.90\n",
      "19   86419.70       153514.11             0.00    New York  122776.86\n",
      "20   76253.86       113867.30        298664.47  California  118474.03\n",
      "21   78389.47       153773.43        299737.29    New York  111313.02\n",
      "22   73994.56       122782.75        303319.26     Florida  110352.25\n",
      "23   67532.53       105751.03        304768.73     Florida  108733.99\n",
      "24   77044.01        99281.34        140574.81    New York  108552.04\n",
      "25   64664.71       139553.16        137962.62  California  107404.34\n",
      "26   75328.87       144135.98        134050.07     Florida  105733.54\n",
      "27   72107.60       127864.55        353183.81    New York  105008.31\n",
      "28   66051.52       182645.56        118148.20     Florida  103282.38\n",
      "29   65605.48       153032.06        107138.38    New York  101004.64\n",
      "30   61994.48       115641.28         91131.24     Florida   99937.59\n",
      "31   61136.38       152701.92         88218.23    New York   97483.56\n",
      "32   63408.86       129219.61         46085.25  California   97427.84\n",
      "33   55493.95       103057.49        214634.81     Florida   96778.92\n",
      "34   46426.07       157693.92        210797.67  California   96712.80\n",
      "35   46014.02        85047.44        205517.64    New York   96479.51\n",
      "36   28663.76       127056.21        201126.82     Florida   90708.19\n",
      "37   44069.95        51283.14        197029.42  California   89949.14\n",
      "38   20229.59        65947.93        185265.10    New York   81229.06\n",
      "39   38558.51        82982.09        174999.30  California   81005.76\n",
      "40   28754.33       118546.05        172795.67  California   78239.91\n",
      "41   27892.92        84710.77        164470.71     Florida   77798.83\n",
      "42   23640.93        96189.63        148001.11  California   71498.49\n",
      "43   15505.73       127382.30         35534.17    New York   69758.98\n",
      "44   22177.74       154806.14         28334.72  California   65200.33\n",
      "45    1000.23       124153.04          1903.93    New York   64926.08\n",
      "46    1315.46       115816.21        297114.46     Florida   49490.75\n",
      "47       0.00       135426.92             0.00  California   42559.73\n",
      "48     542.05        51743.15             0.00    New York   35673.41\n",
      "49       0.00       116983.80         45173.06  California   14681.40\n",
      "X\n",
      "[[165349.2 136897.8 471784.1 'New York']\n",
      " [162597.7 151377.59 443898.53 'California']\n",
      " [153441.51 101145.55 407934.54 'Florida']\n",
      " [144372.41 118671.85 383199.62 'New York']\n",
      " [142107.34 91391.77 366168.42 'Florida']\n",
      " [131876.9 99814.71 362861.36 'New York']\n",
      " [134615.46 147198.87 127716.82 'California']\n",
      " [130298.13 145530.06 323876.68 'Florida']\n",
      " [120542.52 148718.95 311613.29 'New York']\n",
      " [123334.88 108679.17 304981.62 'California']\n",
      " [101913.08 110594.11 229160.95 'Florida']\n",
      " [100671.96 91790.61 249744.55 'California']\n",
      " [93863.75 127320.38 249839.44 'Florida']\n",
      " [91992.39 135495.07 252664.93 'California']\n",
      " [119943.24 156547.42 256512.92 'Florida']\n",
      " [114523.61 122616.84 261776.23 'New York']\n",
      " [78013.11 121597.55 264346.06 'California']\n",
      " [94657.16 145077.58 282574.31 'New York']\n",
      " [91749.16 114175.79 294919.57 'Florida']\n",
      " [86419.7 153514.11 0.0 'New York']\n",
      " [76253.86 113867.3 298664.47 'California']\n",
      " [78389.47 153773.43 299737.29 'New York']\n",
      " [73994.56 122782.75 303319.26 'Florida']\n",
      " [67532.53 105751.03 304768.73 'Florida']\n",
      " [77044.01 99281.34 140574.81 'New York']\n",
      " [64664.71 139553.16 137962.62 'California']\n",
      " [75328.87 144135.98 134050.07 'Florida']\n",
      " [72107.6 127864.55 353183.81 'New York']\n",
      " [66051.52 182645.56 118148.2 'Florida']\n",
      " [65605.48 153032.06 107138.38 'New York']\n",
      " [61994.48 115641.28 91131.24 'Florida']\n",
      " [61136.38 152701.92 88218.23 'New York']\n",
      " [63408.86 129219.61 46085.25 'California']\n",
      " [55493.95 103057.49 214634.81 'Florida']\n",
      " [46426.07 157693.92 210797.67 'California']\n",
      " [46014.02 85047.44 205517.64 'New York']\n",
      " [28663.76 127056.21 201126.82 'Florida']\n",
      " [44069.95 51283.14 197029.42 'California']\n",
      " [20229.59 65947.93 185265.1 'New York']\n",
      " [38558.51 82982.09 174999.3 'California']\n",
      " [28754.33 118546.05 172795.67 'California']\n",
      " [27892.92 84710.77 164470.71 'Florida']\n",
      " [23640.93 96189.63 148001.11 'California']\n",
      " [15505.73 127382.3 35534.17 'New York']\n",
      " [22177.74 154806.14 28334.72 'California']\n",
      " [1000.23 124153.04 1903.93 'New York']\n",
      " [1315.46 115816.21 297114.46 'Florida']\n",
      " [0.0 135426.92 0.0 'California']\n",
      " [542.05 51743.15 0.0 'New York']\n",
      " [0.0 116983.8 45173.06 'California']]\n",
      "Y\n",
      "[192261.83 191792.06 191050.39 182901.99 166187.94 156991.12 156122.51\n",
      " 155752.6  152211.77 149759.96 146121.95 144259.4  141585.52 134307.35\n",
      " 132602.65 129917.04 126992.93 125370.37 124266.9  122776.86 118474.03\n",
      " 111313.02 110352.25 108733.99 108552.04 107404.34 105733.54 105008.31\n",
      " 103282.38 101004.64  99937.59  97483.56  97427.84  96778.92  96712.8\n",
      "  96479.51  90708.19  89949.14  81229.06  81005.76  78239.91  77798.83\n",
      "  71498.49  69758.98  65200.33  64926.08  49490.75  42559.73  35673.41\n",
      "  14681.4 ]\n"
     ]
    }
   ],
   "source": [
    "# Load dataset (50_Startups).\n",
    "dataset = pd.read_csv(r\"../dataset/50_Startups.csv\")\n",
    "X = dataset.iloc[:, :-1].values # [row, column]\n",
    "Y = dataset.iloc[:, -1].values\n",
    "print(\"Dataset\", dataset, \"X\", X, \"Y\", Y, sep=\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6c23eaa7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.0 0.0 1.0 165349.2 136897.8 471784.1]\n",
      " [1.0 0.0 0.0 162597.7 151377.59 443898.53]\n",
      " [0.0 1.0 0.0 153441.51 101145.55 407934.54]\n",
      " [0.0 0.0 1.0 144372.41 118671.85 383199.62]\n",
      " [0.0 1.0 0.0 142107.34 91391.77 366168.42]\n",
      " [0.0 0.0 1.0 131876.9 99814.71 362861.36]\n",
      " [1.0 0.0 0.0 134615.46 147198.87 127716.82]\n",
      " [0.0 1.0 0.0 130298.13 145530.06 323876.68]\n",
      " [0.0 0.0 1.0 120542.52 148718.95 311613.29]\n",
      " [1.0 0.0 0.0 123334.88 108679.17 304981.62]\n",
      " [0.0 1.0 0.0 101913.08 110594.11 229160.95]\n",
      " [1.0 0.0 0.0 100671.96 91790.61 249744.55]\n",
      " [0.0 1.0 0.0 93863.75 127320.38 249839.44]\n",
      " [1.0 0.0 0.0 91992.39 135495.07 252664.93]\n",
      " [0.0 1.0 0.0 119943.24 156547.42 256512.92]\n",
      " [0.0 0.0 1.0 114523.61 122616.84 261776.23]\n",
      " [1.0 0.0 0.0 78013.11 121597.55 264346.06]\n",
      " [0.0 0.0 1.0 94657.16 145077.58 282574.31]\n",
      " [0.0 1.0 0.0 91749.16 114175.79 294919.57]\n",
      " [0.0 0.0 1.0 86419.7 153514.11 0.0]\n",
      " [1.0 0.0 0.0 76253.86 113867.3 298664.47]\n",
      " [0.0 0.0 1.0 78389.47 153773.43 299737.29]\n",
      " [0.0 1.0 0.0 73994.56 122782.75 303319.26]\n",
      " [0.0 1.0 0.0 67532.53 105751.03 304768.73]\n",
      " [0.0 0.0 1.0 77044.01 99281.34 140574.81]\n",
      " [1.0 0.0 0.0 64664.71 139553.16 137962.62]\n",
      " [0.0 1.0 0.0 75328.87 144135.98 134050.07]\n",
      " [0.0 0.0 1.0 72107.6 127864.55 353183.81]\n",
      " [0.0 1.0 0.0 66051.52 182645.56 118148.2]\n",
      " [0.0 0.0 1.0 65605.48 153032.06 107138.38]\n",
      " [0.0 1.0 0.0 61994.48 115641.28 91131.24]\n",
      " [0.0 0.0 1.0 61136.38 152701.92 88218.23]\n",
      " [1.0 0.0 0.0 63408.86 129219.61 46085.25]\n",
      " [0.0 1.0 0.0 55493.95 103057.49 214634.81]\n",
      " [1.0 0.0 0.0 46426.07 157693.92 210797.67]\n",
      " [0.0 0.0 1.0 46014.02 85047.44 205517.64]\n",
      " [0.0 1.0 0.0 28663.76 127056.21 201126.82]\n",
      " [1.0 0.0 0.0 44069.95 51283.14 197029.42]\n",
      " [0.0 0.0 1.0 20229.59 65947.93 185265.1]\n",
      " [1.0 0.0 0.0 38558.51 82982.09 174999.3]\n",
      " [1.0 0.0 0.0 28754.33 118546.05 172795.67]\n",
      " [0.0 1.0 0.0 27892.92 84710.77 164470.71]\n",
      " [1.0 0.0 0.0 23640.93 96189.63 148001.11]\n",
      " [0.0 0.0 1.0 15505.73 127382.3 35534.17]\n",
      " [1.0 0.0 0.0 22177.74 154806.14 28334.72]\n",
      " [0.0 0.0 1.0 1000.23 124153.04 1903.93]\n",
      " [0.0 1.0 0.0 1315.46 115816.21 297114.46]\n",
      " [1.0 0.0 0.0 0.0 135426.92 0.0]\n",
      " [0.0 0.0 1.0 542.05 51743.15 0.0]\n",
      " [1.0 0.0 0.0 0.0 116983.8 45173.06]]\n"
     ]
    }
   ],
   "source": [
    "# We have categorical string data which need to be, converted.\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "ct = ColumnTransformer(transformers=[('encoder', OneHotEncoder(), [3])],remainder='passthrough')\n",
    "X = ct.fit_transform(X)\n",
    "print(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "47abf1f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare testing and training dataset.\n",
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, Y, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37b1c5dc",
   "metadata": {},
   "source": [
    "## Train Multiple Linear Regression Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "eee06600",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression()"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "regressor = LinearRegression()\n",
    "regressor.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31c18ebc",
   "metadata": {},
   "source": [
    "## Test Multiple Linear Regression Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ade2eb36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[103015.20159796 132582.27760816 132447.73845174  71976.09851258\n",
      " 178537.48221055 116161.24230166  67851.69209676  98791.73374686\n",
      " 113969.43533013 167921.06569551]\n"
     ]
    }
   ],
   "source": [
    "y_pred = regressor.predict(x_test)\n",
    "print(y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a89a8f8",
   "metadata": {},
   "source": [
    "## Check training dataset with testing dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0c049fd3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[103015.2  103282.38]\n",
      " [132582.28 144259.4 ]\n",
      " [132447.74 146121.95]\n",
      " [ 71976.1   77798.83]\n",
      " [178537.48 191050.39]\n",
      " [116161.24 105008.31]\n",
      " [ 67851.69  81229.06]\n",
      " [ 98791.73  97483.56]\n",
      " [113969.44 110352.25]\n",
      " [167921.07 166187.94]]\n"
     ]
    }
   ],
   "source": [
    "np.set_printoptions(precision=2)\n",
    "y_pred_vertical = y_pred.reshape(len(y_pred), 1)\n",
    "y_test_vertical = y_test.reshape(len(y_test), 1)\n",
    "print(np.concatenate((y_pred_vertical, y_test_vertical), 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a69d6c9f",
   "metadata": {},
   "source": [
    "## Test with new data\n",
    "- With given details like\n",
    "    - Spend = 160000\n",
    "    - Administration Spend = 130000\n",
    "    - Marketing Spend = 300000\n",
    "    - State = 'California' -> (1, 0, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "969a4ba5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[181566.92]\n"
     ]
    }
   ],
   "source": [
    "new_prediction = regressor.predict([[1, 0, 0, 160000, 130000, 300000]])\n",
    "print(new_prediction)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18c3e140",
   "metadata": {},
   "source": [
    "Therefore, our model predicts that the profit of a Californian startup which spent 160000 in R&D, 130000 in Administration and 300000 in Marketing is $ 181566,92.\n",
    "\n",
    "**Important note 1:** Notice that the values of the features were all input in a double pair of square brackets. That's because the \"predict\" method always expects a 2D array as the format of its inputs. And putting our values into a double pair of square brackets makes the input exactly a 2D array. Simply put:\n",
    "\n",
    "$1, 0, 0, 160000, 130000, 300000 \\rightarrow \\textrm{scalars}$\n",
    "\n",
    "$[1, 0, 0, 160000, 130000, 300000] \\rightarrow \\textrm{1D array}$\n",
    "\n",
    "$[[1, 0, 0, 160000, 130000, 300000]] \\rightarrow \\textrm{2D array}$\n",
    "\n",
    "**Important note 2:** Notice also that the \"California\" state was not input as a string in the last column but as \"1, 0, 0\" in the first three columns. That's because of course the predict method expects the one-hot-encoded values of the state, and as we see in the second row of the matrix of features X, \"California\" was encoded as \"1, 0, 0\". And be careful to include these values in the first three columns, not the last three ones, because the dummy variables are always created in the first columns."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23b13eec",
   "metadata": {},
   "source": [
    "## We can even get the Coefficient of the equation\n",
    "- These coefficient are create automatically by the class LinearRegression\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "871857d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b0 = 42467.52924854249\n",
      "b1-n = [ 8.66e+01 -8.73e+02  7.86e+02  7.73e-01  3.29e-02  3.66e-02]\n",
      "Then our final equation can we written as :\n",
      "profit (y) = 42467.52924854249 + (86.63836918478817 * D1) + (-872.6457908797435 * D2) + (786.0074216944598 * D3) + (0.7734671927326701 * R&D Spend as x1) + (0.7734671927326701 * Administration as x2) + (0.7734671927326701 * Marketing Spend as x3) \n"
     ]
    }
   ],
   "source": [
    "print(\"b0 =\", regressor.intercept_)\n",
    "print(\"b1-n =\", regressor.coef_)\n",
    "\n",
    "print(\"Then our final equation can we written as :\")\n",
    "print(f\"profit (y) = {regressor.intercept_} + ({regressor.coef_[0]} * D1) + ({regressor.coef_[1]} * D2) + ({regressor.coef_[2]} * D3) + ({regressor.coef_[3]} * R&D Spend as x1) + ({regressor.coef_[3]} * Administration as x2) + ({regressor.coef_[3]} * Marketing Spend as x3) \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09a00a9d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
