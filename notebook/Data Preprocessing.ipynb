{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Data Preprocessing\r\n",
    "\r\n",
    "- Before going to any Machine Learning Algorithm, we need to do Data Preprocessing steps\r\n",
    "    - Import dataset from the CSV file.  \r\n",
    "    - Split Feature variable (X) & Depended variable (Y).  \r\n",
    "    - Replace missing data.  \r\n",
    "    - Replace string or categorical data.  \r\n",
    "    - Feature scaling.  \r\n",
    "    - Split training and test dataset.  "
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Import dataset from the CSV file. \r\n",
    "\r\n",
    "- We are using CSV as our dataset file & with the help of the pandas module, we can easily read CSV and have it in a variable called a Dataframe. \r\n",
    "- Dataframe is a cool type provided by pandas where we can do complex operations on any dataset."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "import numpy as np\r\n",
    "import matplotlib.pyplot as plt\r\n",
    "import pandas as pd \r\n",
    "dataset = pd.read_csv(r\"../dataset/Data.csv\")\r\n",
    "print(dataset)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "   Country   Age   Salary Purchased\n",
      "0   France  44.0  72000.0        No\n",
      "1    Spain  27.0  48000.0       Yes\n",
      "2  Germany  30.0  54000.0        No\n",
      "3    Spain  38.0  61000.0        No\n",
      "4  Germany  40.0      NaN       Yes\n",
      "5   France  35.0  58000.0       Yes\n",
      "6    Spain   NaN  52000.0        No\n",
      "7   France  48.0  79000.0       Yes\n",
      "8  Germany  50.0  83000.0        No\n",
      "9   France  37.0  67000.0       Yes\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Split Feature variable (X) & Depended variable (Y).  \r\n",
    "\r\n",
    "- Feature variable, in-depended variable, input variable are represented as X in the code, which helps to predict Y.\r\n",
    "- Depended variable, output variable are represented as Y in the code, which is the expected prediction from the X.  \r\n",
    "- Most commonly last comlumn will be the depended variable Y rest of them will be feature variable X.\r\n",
    "- So, we are spliting the given dataset into X and Y."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "X = dataset.iloc[:, :-1].values # [row, column]\r\n",
    "Y = dataset.iloc[:, -1].values\r\n",
    "print(\"X\", X, \"Y\", Y, sep=\"\\n\")"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "X\n",
      "[['France' 44.0 72000.0]\n",
      " ['Spain' 27.0 48000.0]\n",
      " ['Germany' 30.0 54000.0]\n",
      " ['Spain' 38.0 61000.0]\n",
      " ['Germany' 40.0 nan]\n",
      " ['France' 35.0 58000.0]\n",
      " ['Spain' nan 52000.0]\n",
      " ['France' 48.0 79000.0]\n",
      " ['Germany' 50.0 83000.0]\n",
      " ['France' 37.0 67000.0]]\n",
      "Y\n",
      "['No' 'Yes' 'No' 'No' 'Yes' 'Yes' 'No' 'Yes' 'No' 'Yes']\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Replace missing data\r\n",
    "- As you can see there are some of the cell are empty and they are filled with ```nan``` \r\n",
    "- We need to eleminate or replace those empty cells with the ```strategy```\r\n",
    "- Yes, there are many ```strategy``` like [\"mean\", \"median\", \"most_frequent\", \"constant\"]\r\n",
    "- But, we are going to use mean strategy to replace all the missing datas."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "from sklearn.impute import SimpleImputer\r\n",
    "imputer = SimpleImputer(missing_values=np.nan, strategy=\"mean\")\r\n",
    "imputer.fit(X[:, 1:2+1])\r\n",
    "X[:, 1:2+1] = imputer.transform(X[:, 1:2+1])\r\n",
    "print(X)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[['France' 44.0 72000.0]\n",
      " ['Spain' 27.0 48000.0]\n",
      " ['Germany' 30.0 54000.0]\n",
      " ['Spain' 38.0 61000.0]\n",
      " ['Germany' 40.0 63777.77777777778]\n",
      " ['France' 35.0 58000.0]\n",
      " ['Spain' 38.77777777777778 52000.0]\n",
      " ['France' 48.0 79000.0]\n",
      " ['Germany' 50.0 83000.0]\n",
      " ['France' 37.0 67000.0]]\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Replace string data\r\n",
    "- We can't perform any algorithm with the string data so we need to convert those string data into some other algorithm understandable format\r\n",
    "- Before that we can understand that you dataset have two type of string data columns which are [\"Country\", \"Purchased\"]\r\n",
    "- Where, ```Country``` is the categorical string data where only 3 category countries are repeating again and again.\r\n",
    "- Where as, ```Purchased``` is the lable string data where it is more over look like boolean data.\r\n",
    "- So, we are replaceing Country column as vector eg : ```(0, 0, 1)``` with the help of ```ColumnTransformer``` & ```OneHotEncoder``` similarly replacing Purchased column as ```0 & 1``` with the help of ```LabelEncoder```."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Tranform feature's Country column\r\n",
    "- Since our Country is categorical we are convergting that into Vector ```Example : (1.0 0.0 0.0) for France``` \r\n",
    "- We are using sklearn's ```ColumnTransformer``` for tranform the column from the feature and ```OneHotEncoder``` as the preprocessor to convert string data into vetor.\r\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "from sklearn.compose import ColumnTransformer\r\n",
    "from sklearn.preprocessing import OneHotEncoder\r\n",
    "ct = ColumnTransformer(transformers=[('encoder', OneHotEncoder(), [0])],remainder='passthrough')\r\n",
    "X = ct.fit_transform(X)\r\n",
    "print(X)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[[1.0 0.0 0.0 44.0 72000.0]\n",
      " [0.0 0.0 1.0 27.0 48000.0]\n",
      " [0.0 1.0 0.0 30.0 54000.0]\n",
      " [0.0 0.0 1.0 38.0 61000.0]\n",
      " [0.0 1.0 0.0 40.0 63777.77777777778]\n",
      " [1.0 0.0 0.0 35.0 58000.0]\n",
      " [0.0 0.0 1.0 38.77777777777778 52000.0]\n",
      " [1.0 0.0 0.0 48.0 79000.0]\n",
      " [0.0 1.0 0.0 50.0 83000.0]\n",
      " [1.0 0.0 0.0 37.0 67000.0]]\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Tranform depended variable's Purchased column\r\n",
    "- As we know Purchased column is more like boolean we can label them as 0 & 1.\r\n",
    "- To do that Label encoding we are using sklearn's ```LabelEncoder``` which encode the dataset and tranform the same."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "from sklearn.preprocessing import LabelEncoder\r\n",
    "le = LabelEncoder()\r\n",
    "Y = le.fit_transform(Y)\r\n",
    "print(Y)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[0 1 0 0 1 1 0 1 0 1]\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Split dataset into training and test set"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "from sklearn.model_selection import train_test_split\r\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, Y, test_size=0.2) # random_state=1 to don't shuffle the datasets"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "print(\"X Train\", x_train, \"Y Train\", y_train, sep=\"\\n\")"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "X Train\n",
      "[[0.0 1.0 0.0 50.0 83000.0]\n",
      " [1.0 0.0 0.0 35.0 58000.0]\n",
      " [0.0 0.0 1.0 38.77777777777778 52000.0]\n",
      " [1.0 0.0 0.0 37.0 67000.0]\n",
      " [1.0 0.0 0.0 48.0 79000.0]\n",
      " [0.0 0.0 1.0 27.0 48000.0]\n",
      " [0.0 1.0 0.0 40.0 63777.77777777778]\n",
      " [0.0 1.0 0.0 30.0 54000.0]]\n",
      "Y Train\n",
      "[0 1 0 1 1 1 1 0]\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "print(\"X Test\", x_test, \"Y Test\", y_test, sep=\"\\n\")"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "X Test\n",
      "[[0.0 0.0 1.0 38.0 61000.0]\n",
      " [1.0 0.0 0.0 44.0 72000.0]]\n",
      "Y Test\n",
      "[0 0]\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Feature scaling"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "from sklearn.preprocessing import StandardScaler\r\n",
    "sc = StandardScaler()\r\n",
    "# we only take the large value column which is not in the range of (-3, 3)\r\n",
    "x_train[:, 3:4+1] = sc.fit_transform(x_train[:, 3:4+1])\r\n",
    "x_test[:, 3:4+1] = sc.transform(x_test[:, 3:4+1])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "source": [
    "print(x_train)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[[0.0 1.0 0.0 1.582353946227601 1.6787007930711877]\n",
      " [1.0 0.0 0.0 -0.4329081551000039 -0.42992546479911053]\n",
      " [0.0 0.0 1.0 0.0746393370862078 -0.9359957666879821]\n",
      " [1.0 0.0 0.0 -0.16420654158965658 0.32917998803419685]\n",
      " [1.0 0.0 0.0 1.3136523327172536 1.34132059181194]\n",
      " [0.0 0.0 1.0 -1.507714609141393 -1.2733759679472298]\n",
      " [0.0 1.0 0.0 0.2388458786758644 0.05740149257535867]\n",
      " [0.0 1.0 0.0 -1.1046621888758723 -0.7673056660583583]]\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "source": [
    "print(x_test)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[[0.0 0.0 1.0 -0.02985573483448293 -0.17689031385467474]\n",
      " [1.0 0.0 0.0 0.776249105696559 0.7509052396082565]]\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "b3ba2566441a7c06988d0923437866b63cedc61552a5af99d1f4fb67d367b25f"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.8 64-bit"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}