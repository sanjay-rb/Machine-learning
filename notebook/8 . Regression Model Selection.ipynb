{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regression Model Selection\n",
    "- We have 5 different regression model, but which is best and more effective model/algorithm for the dataset (Combined_Cycle_Power_Plant.csv) ğŸ˜•?\n",
    "- No worries, we answer that question in this **Regression Model Selection** notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## R square (R^2)\n",
    "- R square is the factor that evaluates the result of the model and gives the score out of 1.\n",
    "- If the R^2 score is **higher**, then your model is the **best model** for the given regression dataset.\n",
    "- IF R^2 score is **lower**, then your model is the **worst model** for a given regression dataset. \n",
    "\n",
    "<img src=\"../static/r_squared_eqn.png\" alt=\"r_squared_eqn.png\">\n",
    "\n",
    "### SS-res\n",
    "<img src=\"../static/regression_line.png\" alt=\"regression_line.png\" width=\"500\">\n",
    "\n",
    "### SS-tot\n",
    "<img src=\"../static/average_line.png\" alt=\"average_line.png\" width=\"500\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data preprocessing\n",
    "\n",
    "âœ”ï¸ Import the necessary libraries.\n",
    "\n",
    "âœ”ï¸ Load dataset (Combined_Cycle_Power_Plant.csv).\n",
    "\n",
    "âŒ Our dataset doesn't have any missing data.\n",
    "\n",
    "âŒ We have categorical string data.\n",
    "\n",
    "âœ”ï¸ We have 9569 data. So, we can split this dataset into testing and training datasets to evaluate the result.\n",
    "\n",
    "âš ï¸ Please apply feature scaling only if required by the regression model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries....\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset....\n",
    "dataset = pd.read_csv(r\"../dataset/Combined_Cycle_Power_Plant.csv\")\n",
    "X = dataset.iloc[:, :-1].values # [row, column]\n",
    "Y = dataset.iloc[:, -1].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split training and testing dataset....\n",
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, Y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train and evaluate the performance of multiple linear regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Comparison of y_test & y_pred\n",
      "[[464.89 464.88]\n",
      " [474.84 470.93]\n",
      " [442.89 440.9 ]\n",
      " ...\n",
      " [464.99 466.88]\n",
      " [440.44 446.38]\n",
      " [454.61 456.18]]\n",
      "R^2 score for Multiple linear regression :  0.9314779032105532\n"
     ]
    }
   ],
   "source": [
    "# Train multiple linear regression model...\n",
    "from sklearn.linear_model import LinearRegression\n",
    "multiple_linear_regressor = LinearRegression()\n",
    "multiple_linear_regressor.fit(x_train, y_train)\n",
    "\n",
    "# Test multiple linear regression model...\n",
    "y_pred = multiple_linear_regressor.predict(x_test)\n",
    "\n",
    "# Check the result...\n",
    "np.set_printoptions(precision=2)\n",
    "print(\"Comparison of y_test & y_pred\", np.concatenate((y_pred.reshape(len(y_pred), 1), y_test.reshape(len(y_test), 1)), 1), sep='\\n')\n",
    "\n",
    "# Find preformance by R^2 score...\n",
    "from sklearn.metrics import r2_score\n",
    "multiple_linear_regression_r2_score = r2_score(y_test, y_pred)\n",
    "print(\"R^2 score for Multiple linear regression : \", multiple_linear_regression_r2_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train and evaluate the performance of polynomial linear regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Comparison of y_test & y_pred\n",
      "[[463.72 464.88]\n",
      " [473.33 470.93]\n",
      " [439.9  440.9 ]\n",
      " ...\n",
      " [463.86 466.88]\n",
      " [441.74 446.38]\n",
      " [454.65 456.18]]\n",
      "R^2 score for Ploynomial linear regression :  0.9459659340126794\n"
     ]
    }
   ],
   "source": [
    "# Converting normal feature x to x^n ...\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "x_ploy_convertor = PolynomialFeatures(degree=5)\n",
    "\n",
    "# Train polynomial linear regression model...\n",
    "from sklearn.linear_model import LinearRegression\n",
    "polynomial_linear_regressor = LinearRegression()\n",
    "polynomial_linear_regressor.fit(x_ploy_convertor.fit_transform(x_train), y_train)\n",
    "\n",
    "# Test polynomial linear regression model...\n",
    "y_pred = polynomial_linear_regressor.predict(x_ploy_convertor.fit_transform(x_test))\n",
    "\n",
    "# Check the result...\n",
    "np.set_printoptions(precision=2)\n",
    "print(\"Comparison of y_test & y_pred\", np.concatenate((y_pred.reshape(len(y_pred), 1), y_test.reshape(len(y_test), 1)), 1), sep='\\n')\n",
    "\n",
    "# Find preformance by R^2 score...\n",
    "from sklearn.metrics import r2_score\n",
    "polynomial_linear_regression_r2_score = r2_score(y_test, y_pred)\n",
    "print(\"R^2 score for Ploynomial linear regression : \", polynomial_linear_regression_r2_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train and evaluate the performance of (SVR) Support Vector regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Comparison of y_test & y_pred\n",
      "[[464.45 464.88]\n",
      " [475.   470.93]\n",
      " [439.16 440.9 ]\n",
      " ...\n",
      " [464.6  466.88]\n",
      " [441.74 446.38]\n",
      " [454.73 456.18]]\n",
      "R^2 score for SVR linear regression :  0.9481186461013458\n"
     ]
    }
   ],
   "source": [
    "# Feature scaling independent variables\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "x_sc = StandardScaler()\n",
    "scaled_X = x_sc.fit_transform(x_train)\n",
    "\n",
    "# Feature scaling dependent variables\n",
    "y_sc = StandardScaler()\n",
    "scaled_Y = y_sc.fit_transform(y_train.reshape(len(y_train), 1)).ravel()\n",
    "\n",
    "# Train Linear SVR Regression Model\n",
    "from sklearn.svm import SVR\n",
    "svr_regressor = SVR(kernel='rbf')\n",
    "svr_regressor.fit(scaled_X, scaled_Y)\n",
    "\n",
    "# Test Linear SVR Regression Model\n",
    "y_pred = svr_regressor.predict(x_sc.transform(x_test))\n",
    "y_pred = y_sc.inverse_transform(y_pred)\n",
    "\n",
    "# Check the result...\n",
    "np.set_printoptions(precision=2)\n",
    "print(\"Comparison of y_test & y_pred\", np.concatenate((y_pred.reshape(len(y_pred), 1), y_test.reshape(len(y_test), 1)), 1), sep='\\n')\n",
    "\n",
    "# Find preformance by R^2 score...\n",
    "from sklearn.metrics import r2_score\n",
    "svr_linear_regression_r2_score = r2_score(y_test, y_pred)\n",
    "print(\"R^2 score for SVR linear regression : \", svr_linear_regression_r2_score)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train and evaluate the performance of Decision Tree Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Comparison of y_test & y_pred\n",
      "[[464.51 464.88]\n",
      " [470.35 470.93]\n",
      " [440.74 440.9 ]\n",
      " ...\n",
      " [465.09 466.88]\n",
      " [450.46 446.38]\n",
      " [456.03 456.18]]\n",
      "R^2 score for Decision tree regression :  0.9350941614063605\n"
     ]
    }
   ],
   "source": [
    "# Train Decision Tree Regression Model\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "regressor = DecisionTreeRegressor()\n",
    "regressor.fit(x_train, y_train)\n",
    "\n",
    "# Test Decision Tree Regression Model\n",
    "y_pred = regressor.predict(x_test)\n",
    "\n",
    "# Check the result...\n",
    "np.set_printoptions(precision=2)\n",
    "print(\"Comparison of y_test & y_pred\", np.concatenate((y_pred.reshape(len(y_pred), 1), y_test.reshape(len(y_test), 1)), 1), sep='\\n')\n",
    "\n",
    "# Find preformance by R^2 score...\n",
    "from sklearn.metrics import r2_score\n",
    "decision_tree_regression_r2_score = r2_score(y_test, y_pred)\n",
    "print(\"R^2 score for Decision tree regression : \", decision_tree_regression_r2_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train and evaluate the performance of Random Forest Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Comparison of y_test & y_pred\n",
      "[[464.55 464.88]\n",
      " [471.09 470.93]\n",
      " [438.89 440.9 ]\n",
      " ...\n",
      " [464.81 466.88]\n",
      " [447.32 446.38]\n",
      " [455.3  456.18]]\n",
      "R^2 score for Random forest regression :  0.9619461596044329\n"
     ]
    }
   ],
   "source": [
    "# Train Random Forest Regression Model\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "regressor = RandomForestRegressor(n_estimators = 10) # n_estimators -> number of trees to train the forest\n",
    "regressor.fit(x_train, y_train)\n",
    "\n",
    "# Test Random Forest Regression Model\n",
    "y_pred = regressor.predict(x_test)\n",
    "\n",
    "# Check the result...\n",
    "np.set_printoptions(precision=2)\n",
    "print(\"Comparison of y_test & y_pred\", np.concatenate((y_pred.reshape(len(y_pred), 1), y_test.reshape(len(y_test), 1)), 1), sep='\\n')\n",
    "\n",
    "# Find preformance by R^2 score...\n",
    "from sklearn.metrics import r2_score\n",
    "random_forest_regression_r2_score = r2_score(y_test, y_pred)\n",
    "print(\"R^2 score for Random forest regression : \", random_forest_regression_r2_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Which is best for given dataset ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multiple Linear Regression with r^2 score 0.9314779032105532\n",
      "Ploynomial Linear Regression with r^2 score 0.9459659340126794\n",
      "SVR with r^2 score 0.9481186461013458\n",
      "Decision Tree Regression with r^2 score 0.9350941614063605\n",
      "Random Forest Regression with r^2 score 0.9619461596044329\n",
      "ğŸ‰ğŸ‰ğŸ‰ğŸ‰ğŸ‰ğŸ‰ğŸ‰ğŸ‰ğŸ‰ğŸ‰ğŸ‰ğŸ‰ğŸ‰ğŸ‰ğŸ‰ğŸ‰ğŸ‰ğŸ‰ğŸ‰ğŸ‰ğŸ‰ğŸ‰ğŸ‰ğŸ‰ğŸ‰ğŸ‰ğŸ‰ğŸ‰ğŸ‰ğŸ‰ğŸ‰ğŸ‰ğŸ‰ğŸ‰ğŸ‰ğŸ‰ğŸ‰ğŸ‰ğŸ‰ğŸ‰ğŸ‰ğŸ‰ğŸ‰ğŸ‰ğŸ‰ğŸ‰ğŸ‰ğŸ‰\n",
      "Random Forest Regression is the best model for given dataset ğŸ¥³ with R^2 score 0.9619461596044329\n",
      "ğŸ‰ğŸ‰ğŸ‰ğŸ‰ğŸ‰ğŸ‰ğŸ‰ğŸ‰ğŸ‰ğŸ‰ğŸ‰ğŸ‰ğŸ‰ğŸ‰ğŸ‰ğŸ‰ğŸ‰ğŸ‰ğŸ‰ğŸ‰ğŸ‰ğŸ‰ğŸ‰ğŸ‰ğŸ‰ğŸ‰ğŸ‰ğŸ‰ğŸ‰ğŸ‰ğŸ‰ğŸ‰ğŸ‰ğŸ‰ğŸ‰ğŸ‰ğŸ‰ğŸ‰ğŸ‰ğŸ‰ğŸ‰ğŸ‰ğŸ‰ğŸ‰ğŸ‰ğŸ‰ğŸ‰ğŸ‰\n"
     ]
    }
   ],
   "source": [
    "r2_scores = {\n",
    "    \"Multiple Linear Regression\" : multiple_linear_regression_r2_score, \n",
    "    \"Ploynomial Linear Regression\" : polynomial_linear_regression_r2_score, \n",
    "    \"SVR\" : svr_linear_regression_r2_score, \n",
    "    \"Decision Tree Regression\" : decision_tree_regression_r2_score, \n",
    "    \"Random Forest Regression\" : random_forest_regression_r2_score\n",
    "}\n",
    "# Print final result of all model....\n",
    "for model, r2 in r2_scores.items():\n",
    "    print(f\"{model} with r^2 score {r2}\")\n",
    "\n",
    "# find best of them....\n",
    "best_of_them = max(r2_scores.values())\n",
    "\n",
    "# Print best of them....\n",
    "for model, r2 in r2_scores.items():\n",
    "    if r2 == best_of_them:\n",
    "        print_me=f\"{model} is the best model for given dataset ğŸ¥³ with R^2 score {r2}\"\n",
    "        print(\"ğŸ‰\" * (len(print_me) // 2))\n",
    "        print(print_me)\n",
    "        print(\"ğŸ‰\" * (len(print_me) // 2))\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note:** Above result is only for the dataset (Combined_Cycle_Power_Plant.csv) which we were given as the input. If you change the dataset, the result also changes certainly."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pros & Cons\n",
    "\n",
    "<img src=\"../static/pros_cons.png\" alt=\"pros_cons.png\" width=\"800\">"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "b3ba2566441a7c06988d0923437866b63cedc61552a5af99d1f4fb67d367b25f"
  },
  "kernelspec": {
   "display_name": "Python 3.8.8 64-bit ('base': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
